name: Hourly Scraping and Convex Ingestion

on:
  schedule:
    - cron: "0 * * * *"
  workflow_dispatch:

concurrency:
  group: scrape-hourly
  cancel-in-progress: false

jobs:
  scrape-and-ingest:
    runs-on: ubuntu-latest
    env:
      ALLOW_SUSPICIOUS_DATA: "false"
      CI: "true"
      CONVEX_INGEST_SECRET: ${{ secrets.CONVEX_INGEST_SECRET }}
      CONVEX_URL: ${{ secrets.CONVEX_URL }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Bun
        uses: oven-sh/setup-bun@v2
        with:
          bun-version: latest

      - name: Install dependencies
        run: bun install --frozen-lockfile

      - name: Run scrapers with retry
        run: |
          set -euo pipefail

          run_with_retry() {
            local command="$1"
            local max_attempts=3
            local attempt=1

            while true; do
              echo "Attempt ${attempt}/${max_attempts}: ${command}"
              if eval "$command"; then
                return 0
              fi

              if [ "$attempt" -ge "$max_attempts" ]; then
                echo "Command failed after ${max_attempts} attempts: ${command}" >&2
                return 1
              fi

              sleep_seconds=$(( attempt * 20 ))
              echo "Retrying in ${sleep_seconds}s..."
              sleep "$sleep_seconds"
              attempt=$(( attempt + 1 ))
            done
          }

          run_with_retry "bun run bin/scrape-mortgage-rates.ts"
          run_with_retry "bun run bin/scrape-personal-loan-rates.ts"
          run_with_retry "bun run bin/scrape-car-loan-rates.ts"
          run_with_retry "bun run bin/scrape-credit-card-rates.ts"
